{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2593ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_folds = 5\n",
    "num_epochs = 25\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4172dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "torch.manual_seed(42)\n",
    "\n",
    "image_folder_path = \"C:/Users/Sahilur Rahman/OneDrive/Desktop/Tumor_Cellularity/20X_ROIs/\"  \n",
    "transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(),\n",
    "        T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.20),\n",
    "        T.RandomRotation(degrees=(-45, 45)),\n",
    "        T.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=(-10, 10)),\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=image_folder_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69beca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "n_inputs = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a265de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('--------------------------------')\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = SubsetRandomSampler(test_ids)\n",
    "    trainloader = DataLoader(dataset, batch_size=128, sampler=train_subsampler)\n",
    "    testloader = DataLoader(dataset, batch_size=128, sampler=test_subsampler)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "      \n",
    "        print(f'Starting epoch {epoch + 1}')\n",
    "        current_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "    print('Starting testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc758131",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "targets_list = []\n",
    "with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "        precision = precision_score(targets_list, predictions, average='macro')\n",
    "        recall = recall_score(targets_list, predictions, average='macro')\n",
    "        f1 = f1_score(targets_list, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "print('Precision for fold %d: %.3f' % (fold, precision))\n",
    "print('Recall for fold %d: %.3f' % (fold, recall))\n",
    "print('F1-score for fold %d: %.3f' % (fold, f1))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results['accuracy'].append(100.0 * (correct / total))\n",
    "results['precision'].append(precision)\n",
    "results['recall'].append(recall)\n",
    "results['f1'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "for metric, values in results.items():\n",
    "    avg_metric = np.mean(values)\n",
    "    std_metric = np.std(values)\n",
    "    print(f'Average {metric}: {avg_metric:.3f} Â± {std_metric:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4460164,
     "sourceId": 7650840,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13831.247535,
   "end_time": "2024-02-21T13:30:00.346321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-21T09:39:29.098786",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
